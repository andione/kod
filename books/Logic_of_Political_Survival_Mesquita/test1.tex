\documentclass[12pt,fleqn]{article}\usepackage{common}
\begin{document}

\begin{minted}[fontsize=\footnotesize]{python}
import pandas as pd
df = pd.read_csv('bdm2s2_nation_year_data_may2002.csv')
df['Klepto'] = (df['TAXGDP']-df['Expenditure']).abs()
df[['regyr','ccode','aid_gdp','pop','year','W','S','WS','Klepto']].to_csv('/tmp/out.csv')
\end{minted}

\begin{minted}[fontsize=\footnotesize]{python}
import statsmodels.formula.api as smf
results = smf.ols('Klepto ~ W + S + aid_gdp + np.log(pop)', data=df).fit()
print results.summary()
\end{minted}

\begin{verbatim}
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                 Klepto   R-squared:                       0.205
Model:                            OLS   Adj. R-squared:                  0.202
Method:                 Least Squares   F-statistic:                     65.82
Date:                Mon, 06 Apr 2015   Prob (F-statistic):           1.43e-49
Time:                        20:07:21   Log-Likelihood:                -3297.9
No. Observations:                1027   AIC:                             6606.
Df Residuals:                    1022   BIC:                             6630.
Df Model:                           4                                         
Covariance Type:            nonrobust                                         
===============================================================================
                  coef    std err          t      P>|t|      [95.0% Conf. Int.]
-------------------------------------------------------------------------------
Intercept       4.8089      1.223      3.933      0.000         2.410     7.208
W              -3.9128      0.879     -4.453      0.000        -5.637    -2.189
S               3.9783      0.675      5.892      0.000         2.653     5.303
aid_gdp        39.3581      2.858     13.770      0.000        33.750    44.967
np.log(pop)    -0.1965      0.115     -1.702      0.089        -0.423     0.030
==============================================================================
Omnibus:                      510.462   Durbin-Watson:                   0.657
Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3672.715
Skew:                           2.179   Prob(JB):                         0.00
Kurtosis:                      11.176   Cond. No.                         141.
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
\end{verbatim}

\begin{minted}[fontsize=\footnotesize]{python}
%load_ext rpy2.ipython
%R library(lme4)
\end{minted}

\begin{minted}[fontsize=\footnotesize]{python}
%R -i df2
%R resp_lmer <- resp_lmer <- lmer(Klepto ~ W + S + ( 1 + W + S| regyr), data = df2)
%R -o res res = summary(resp_lmer)
print res
\end{minted}

\begin{verbatim}
Linear mixed model fit by REML ['lmerMod']
Formula: Klepto ~ W + S + (1 + W + S | regyr)
   Data: df2

REML criterion at convergence: 11852.2

Scaled residuals: 
    Min      1Q  Median      3Q     Max 
-4.4516 -0.2923 -0.1179  0.1457 11.7616 

Random effects:
 Groups   Name        Variance Std.Dev. Corr       
 regyr    (Intercept)  60.62    7.786              
          W           599.46   24.484   -1.00      
          S           269.06   16.403    1.00 -1.00
 Residual             146.74   12.114              
Number of obs: 1489, groups:  regyr, 125

Fixed effects:
            Estimate Std. Error t value
(Intercept)    8.202      1.186   6.914
W            -12.440      2.741  -4.538
S              8.408      2.047   4.108

Correlation of Fixed Effects:
  (Intr) W     
W -0.619       
S  0.222 -0.884

\end{verbatim}


\end{document}
